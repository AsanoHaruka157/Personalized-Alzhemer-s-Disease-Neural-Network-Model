{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T02:53:32.527436Z",
     "start_time": "2025-03-02T02:53:11.596608Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['AGE'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 132\u001b[0m\n\u001b[0;32m    128\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(merged_rows)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#4. calculating the quantile and normalizing the data\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m name \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGE\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    133\u001b[0m df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mABETA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTAU\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    134\u001b[0m q5 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.05\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\21138\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\21138\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\21138\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['AGE'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. load data\n",
    "# read rawdata.xlsx\n",
    "file_path = 'rawdata.xlsx'\n",
    "adni_org_df = pd.read_excel(file_path, sheet_name='ADNI Org.')\n",
    "csf_biomarker_df = pd.read_excel(file_path, sheet_name='CSF Biomarker')\n",
    "\n",
    "# initialize an empty dataframe\n",
    "df = pd.DataFrame(columns=['RID', 'EXAMDATE', 'AGE', 'ABETA', 'TAU', 'N', 'C'])\n",
    "\n",
    "# processing 'ADNI Org.' sheet to get RID, EXAMDATE, AGE, C, N\n",
    "for index, row in adni_org_df.iterrows():\n",
    "    rid = row['RID']\n",
    "    \n",
    "    # check if there is this RID in 'CSF Biomarker'\n",
    "    if rid in csf_biomarker_df['RID'].values:\n",
    "        # load 'EXAMDATE', 'AGE', 'C', 'N' in 'ADNI Org.'\n",
    "        examdate = row['EXAMDATE']\n",
    "        age = row['AGE']\n",
    "        c = row['C']\n",
    "        n = row['N']\n",
    "        \n",
    "        # combining into result_df\n",
    "        new_row = pd.DataFrame({\n",
    "            'RID': [rid],\n",
    "            'EXAMDATE': [examdate],\n",
    "            'AGE': [age],\n",
    "            'C': [c],\n",
    "            'N': [n],\n",
    "            'ABETA': [None],\n",
    "            'TAU': [None],\n",
    "        })\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# processing 'CSF Biomarker'\n",
    "for index, row in csf_biomarker_df.iterrows():\n",
    "    rid = row['RID']\n",
    "    drwdte = row['DRWDTE']\n",
    "    \n",
    "    # check if there is this RID in 'ADNI Org.'\n",
    "    if rid in adni_org_df['RID'].values:\n",
    "        # check if there  is same RID and DRWDTE in result_df\n",
    "        match = df[(df['RID'] == rid) & (df['EXAMDATE'] == drwdte)]\n",
    "        \n",
    "        if not match.empty:\n",
    "            # if trueï¼Œupload 'ABETA' and 'TAU'\n",
    "            df.loc[match.index, 'ABETA'] = row['ABETA']\n",
    "            df.loc[match.index, 'TAU'] = row['TAU']\n",
    "        else:\n",
    "            # if false, create a new row\n",
    "            new_row = pd.DataFrame({\n",
    "                'RID': [rid],\n",
    "                'EXAMDATE': [drwdte],\n",
    "                'AGE': [None],\n",
    "                'C': [None],\n",
    "                'N': [None],\n",
    "                'ABETA': [row['ABETA']],\n",
    "                'TAU': [row['TAU']]\n",
    "            })\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Sorting\n",
    "df = df[['RID', 'EXAMDATE', 'AGE', 'ABETA', 'TAU', 'N', 'C']]\n",
    "\n",
    "# delete rows whose ABETA, TAU, C, N are all empty or 0\n",
    "condition = (df[['ABETA', 'TAU', 'C', 'N']].isna() | (df[['ABETA', 'TAU', 'C', 'N']] == 0)).all(axis=1)\n",
    "df = df[~condition]\n",
    "\n",
    "# 2.  recalculate the age for each RID, as it's the age at baseline in the document\n",
    "grouped = df.groupby('RID')\n",
    "updated_rows = []\n",
    "\n",
    "for rid, group in grouped:\n",
    "    group = group.sort_values(by='EXAMDATE')\n",
    "    \n",
    "    # get the first EXAMDATE and AGE for the group\n",
    "    first_age = group['AGE'].iloc[0]\n",
    "    \n",
    "    # calculating the AGE for the rest of the rows\n",
    "    for i, row in group.iterrows():\n",
    "        if i == group.index[0]:\n",
    "            # The first line remains the original AGE\n",
    "            updated_rows.append(row)\n",
    "        else:\n",
    "            # calculate the new AGE based on the first EXAMDATE and AGE, keeping one decimal place\n",
    "            date_diff = (row['EXAMDATE'] - group['EXAMDATE'].iloc[0]).days / 365\n",
    "            new_age = round(first_age + date_diff, 1)\n",
    "            row['AGE'] = new_age\n",
    "            updated_rows.append(row)\n",
    "\n",
    "# reassembly\n",
    "df = pd.DataFrame(updated_rows)\n",
    "\n",
    "# delete the rows whose EXAMDATE is empty\n",
    "df = df.replace(0, np.nan)\n",
    "df = df.dropna(subset=['EXAMDATE'])\n",
    "\n",
    "# 3. combining the rows with same RID and AGE\n",
    "grouped = df.groupby(['RID', 'AGE'])\n",
    "# initialize an empty list to store the processed rows\n",
    "merged_rows = []\n",
    "\n",
    "for (rid, age), group in grouped:\n",
    "    group = group.sort_values(by='AGE')\n",
    "    merged_row = {\n",
    "        'RID': rid,\n",
    "        'AGE': group['AGE'].iloc[0],\n",
    "        'ABETA': np.nan,\n",
    "        'TAU': np.nan,\n",
    "        'C': np.nan,\n",
    "        'N': np.nan,\n",
    "    }\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        if not pd.isna(row['ABETA']) or not pd.isna(row['TAU']):\n",
    "            # if there is ABETA or TAU at this time point, fill them in\n",
    "            merged_row['ABETA'] = row['ABETA']\n",
    "            merged_row['TAU'] = row['TAU']\n",
    "        if not pd.isna(row['C']) or not pd.isna(row['N']):\n",
    "            # if there is C or N at this time point, fill them in\n",
    "            merged_row['C'] = row['C']\n",
    "            merged_row['N'] = row['N']\n",
    "\n",
    "    merged_rows.append(merged_row)\n",
    "\n",
    "df = pd.DataFrame(merged_rows)\n",
    "\n",
    "    \n",
    "#4. calculating the quantile and normalizing the data\n",
    "name = df[['RID', 'AGE']]\n",
    "df = df[['ABETA', 'TAU', 'N', 'C']]\n",
    "q5 = df.quantile(0.05)\n",
    "q50 = df.quantile(0.5)\n",
    "q95 = df.quantile(0.95)\n",
    "df = (df - q5)/(q95 - q5) # normalize by 5 and 95 quantile\n",
    "df = pd.concat([name, df], axis=1)\n",
    "with pd.ExcelWriter('data.xlsx', mode='a', engine='openpyxl', if_sheet_exists='replace') as writer: # delete the old sheet to guarantee no residual old data \n",
    "    df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "# save quantile to quantile.npy for convenience\n",
    "q5_df = np.array(q5.values)\n",
    "q95_df = np.array(q95.values)\n",
    "q50_df = np.array(q50.values)\n",
    "q = np.vstack((q5_df.T, q95_df.T, q50_df.T))\n",
    "np.save('quantile.npy', q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
