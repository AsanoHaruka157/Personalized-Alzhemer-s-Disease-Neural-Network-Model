{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T02:53:32.527436Z",
     "start_time": "2025-03-02T02:53:11.596608Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. load data\n",
    "# read rawdata.xlsx\n",
    "file_path = 'rawdata.xlsx'\n",
    "adni_org_df = pd.read_excel(file_path, sheet_name='ADNI Org.')\n",
    "csf_biomarker_df = pd.read_excel(file_path, sheet_name='CSF Biomarker')\n",
    "\n",
    "# initialize an empty dataframe\n",
    "df = pd.DataFrame(columns=['RID', 'EXAMDATE', 'AGE', 'ABETA', 'TAU', 'N', 'C'])\n",
    "\n",
    "# processing 'ADNI Org.' sheet to get RID, EXAMDATE, AGE, C, N\n",
    "for index, row in adni_org_df.iterrows():\n",
    "    rid = row['RID']\n",
    "    \n",
    "    # check if there is this RID in 'CSF Biomarker'\n",
    "    if rid in csf_biomarker_df['RID'].values:\n",
    "        # load 'EXAMDATE', 'AGE', 'C', 'N' in 'ADNI Org.'\n",
    "        examdate = row['EXAMDATE']\n",
    "        age = row['AGE']\n",
    "        c = row['C']\n",
    "        n = row['N']\n",
    "        \n",
    "        # combining into result_df\n",
    "        new_row = pd.DataFrame({\n",
    "            'RID': [rid],\n",
    "            'EXAMDATE': [examdate],\n",
    "            'AGE': [age],\n",
    "            'C': [c],\n",
    "            'N': [n],\n",
    "            'ABETA': [None],\n",
    "            'TAU': [None],\n",
    "        })\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# processing 'CSF Biomarker'\n",
    "for index, row in csf_biomarker_df.iterrows():\n",
    "    rid = row['RID']\n",
    "    drwdte = row['DRWDTE']\n",
    "    \n",
    "    # check if there is this RID in 'ADNI Org.'\n",
    "    if rid in adni_org_df['RID'].values:\n",
    "        # check if there  is same RID and DRWDTE in result_df\n",
    "        match = df[(df['RID'] == rid) & (df['EXAMDATE'] == drwdte)]\n",
    "        \n",
    "        if not match.empty:\n",
    "            # if true，upload 'ABETA' and 'TAU'\n",
    "            df.loc[match.index, 'ABETA'] = row['ABETA']\n",
    "            df.loc[match.index, 'TAU'] = row['TAU']\n",
    "        else:\n",
    "            # if false, create a new row\n",
    "            new_row = pd.DataFrame({\n",
    "                'RID': [rid],\n",
    "                'EXAMDATE': [drwdte],\n",
    "                'AGE': [None],\n",
    "                'C': [None],\n",
    "                'N': [None],\n",
    "                'ABETA': [row['ABETA']],\n",
    "                'TAU': [row['TAU']]\n",
    "            })\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Sorting\n",
    "df = df[['RID', 'EXAMDATE', 'AGE', 'ABETA', 'TAU', 'N', 'C']]\n",
    "\n",
    "# delete rows whose ABETA, TAU, C, N are all empty or 0\n",
    "condition = (df[['ABETA', 'TAU', 'C', 'N']].isna() | (df[['ABETA', 'TAU', 'C', 'N']] == 0)).all(axis=1)\n",
    "df = df[~condition]\n",
    "\n",
    "# 2.  recalculate the age for each RID, as it's the age at baseline in the document\n",
    "grouped = df.groupby('RID')\n",
    "updated_rows = []\n",
    "\n",
    "for rid, group in grouped:\n",
    "    group = group.sort_values(by='EXAMDATE')\n",
    "    \n",
    "    # get the first EXAMDATE and AGE for the group\n",
    "    first_age = group['AGE'].iloc[0]\n",
    "    \n",
    "    # calculating the AGE for the rest of the rows\n",
    "    for i, row in group.iterrows():\n",
    "        if i == group.index[0]:\n",
    "            # The first line remains the original AGE\n",
    "            updated_rows.append(row)\n",
    "        else:\n",
    "            # calculate the new AGE based on the first EXAMDATE and AGE, keeping one decimal place\n",
    "            date_diff = (row['EXAMDATE'] - group['EXAMDATE'].iloc[0]).days / 365\n",
    "            new_age = round(first_age + date_diff, 1)\n",
    "            row['AGE'] = new_age\n",
    "            updated_rows.append(row)\n",
    "\n",
    "# reassembly\n",
    "df = pd.DataFrame(updated_rows)\n",
    "\n",
    "# delete the rows whose EXAMDATE is empty\n",
    "df = df.replace(0, np.nan)\n",
    "df = df.dropna(subset=['EXAMDATE'])\n",
    "\n",
    "# 3. combining the rows with same RID and AGE\n",
    "grouped = df.groupby(['RID', 'AGE'])\n",
    "# initialize an empty list to store the processed rows\n",
    "merged_rows = []\n",
    "\n",
    "for (rid, age), group in grouped:\n",
    "    group = group.sort_values(by='AGE')\n",
    "    merged_row = {\n",
    "        'RID': rid,\n",
    "        'AGE': group['AGE'].iloc[0],\n",
    "        'ABETA': np.nan,\n",
    "        'TAU': np.nan,\n",
    "        'N': np.nan,\n",
    "        'C': np.nan,\n",
    "    }\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        if not pd.isna(row['ABETA']) or not pd.isna(row['TAU']):\n",
    "            # if there is ABETA or TAU at this time point, fill them in\n",
    "            merged_row['ABETA'] = row['ABETA']\n",
    "            merged_row['TAU'] = row['TAU']\n",
    "        if not pd.isna(row['C']) or not pd.isna(row['N']):\n",
    "            # if there is C or N at this time point, fill them in\n",
    "            merged_row['C'] = row['C']\n",
    "            merged_row['N'] = row['N']\n",
    "\n",
    "    merged_rows.append(merged_row)\n",
    "\n",
    "df = pd.DataFrame(merged_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2d6f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique RIDs after filtering: 251\n",
      "Counts of RIDs by number of rows:\n",
      "2 rows: 157 RIDs\n",
      "3 rows: 58 RIDs\n",
      "4 rows: 26 RIDs\n",
      "5 rows: 10 RIDs\n",
      "\n",
      "Summary table:\n",
      "    num_rows  num_RIDs\n",
      "0         2       157\n",
      "1         3        58\n",
      "2         4        26\n",
      "3         5        10\n"
     ]
    }
   ],
   "source": [
    "# 4. 清洗与统计\n",
    "\n",
    "# 4.1 删去 df 中任何列含 NaN 的行（只保留六个关键列都非空的记录）\n",
    "df = df.dropna(subset=['RID', 'AGE', 'ABETA', 'TAU', 'N', 'C'])\n",
    "\n",
    "# 4.2 删除仅有一行数据的 RID\n",
    "rows_per_rid = df.groupby('RID').size()\n",
    "valid_rids = rows_per_rid[rows_per_rid > 1].index\n",
    "df = df[df['RID'].isin(valid_rids)].copy()\n",
    "\n",
    "# 4.3 统计\n",
    "rows_per_rid = df.groupby('RID').size()\n",
    "total_rids = rows_per_rid.index.nunique()\n",
    "rid_count_by_rows = rows_per_rid.value_counts().sort_index()  # 行数 -> 对应 RID 个数\n",
    "\n",
    "print(f\"Total unique RIDs after filtering: {total_rids}\")\n",
    "print(\"Counts of RIDs by number of rows:\")\n",
    "for num_rows, num_rids in rid_count_by_rows.items():\n",
    "    print(f\"{num_rows} rows: {num_rids} RIDs\")\n",
    "\n",
    "# 如需得到一个汇总表：\n",
    "summary_df = rid_count_by_rows.rename_axis('num_rows').reset_index(name='num_RIDs')\n",
    "print(\"\\nSummary table:\\n\", summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828da236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 先生成原始数据表和统计表 ---\n",
    "cols_to_stat = ['ABETA', 'TAU', 'N', 'C']\n",
    "stats = df[cols_to_stat].agg(\n",
    "    ['mean', 'std', lambda x: x.quantile(0.05), lambda x: x.quantile(0.95)]\n",
    ")\n",
    "stats.index = ['mean', 'std', 'y5', 'y95']\n",
    "\n",
    "if \"RID\" in df.columns:\n",
    "    df = df.rename(columns={\"RID\": \"PID\"})\n",
    "rawdata = df.copy()\n",
    "\n",
    "# --- 6. 再对 ABETA, TAU, N, C 做标准化 ---\n",
    "cols_to_standardize = ['ABETA', 'TAU', 'N', 'C']\n",
    "df[cols_to_standardize] = df[cols_to_standardize].apply(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")                   \n",
    "\n",
    "# --- 7. 保存到 data.xlsx ---\n",
    "with pd.ExcelWriter(\"data.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    df.to_excel(writer, index=False)\n",
    "    stats.to_excel(writer, sheet_name=\"stats\")\n",
    "    rawdata.to_excel(writer, sheet_name=\"rawdata\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
